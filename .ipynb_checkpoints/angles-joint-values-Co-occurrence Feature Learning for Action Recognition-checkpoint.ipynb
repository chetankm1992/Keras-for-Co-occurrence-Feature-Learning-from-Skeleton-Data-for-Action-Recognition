{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras import optimizers\n",
    "from utils import *\n",
    "from model import *\n",
    "import matlab.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the model on X,Y,Z on my Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_obj2(frame_l=16, joint_n=25, joint_d=3):\n",
    "\n",
    "    input_joints = Input(name='joints', shape=(frame_l, joint_n, joint_d))\n",
    "    input_joints_diff = Input(name='joints_diff', shape=(frame_l, joint_n, joint_d))\n",
    "    \n",
    "    ##########branch 1##############\n",
    "    x = Conv2D(filters = 32, kernel_size=(1,1),padding='same')(input_joints)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 16, kernel_size=(3,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Permute((1,3,2))(x)\n",
    "    \n",
    "    x = Conv2D(filters = 16, kernel_size=(3,3),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)   \n",
    "    ##########branch 1##############\n",
    "    \n",
    "    ##########branch 2##############Temporal difference\n",
    "    x_d = Conv2D(filters = 32, kernel_size=(1,1),padding='same')(input_joints_diff)\n",
    "    x_d = BatchNormalization()(x_d)\n",
    "    x_d = LeakyReLU()(x_d)\n",
    "    \n",
    "    x_d = Conv2D(filters = 16, kernel_size=(3,1),padding='same')(x_d)\n",
    "    x_d = BatchNormalization()(x_d)\n",
    "    x_d = LeakyReLU()(x_d)\n",
    "\n",
    "    x_d = Permute((1,3,2))(x_d)\n",
    "    \n",
    "    x_d = Conv2D(filters = 16, kernel_size=(3,3),padding='same')(x_d)\n",
    "    x_d = BatchNormalization()(x_d)\n",
    "    x_d = LeakyReLU()(x_d)\n",
    "    ##########branch 2##############\n",
    "    \n",
    "    x = concatenate([x,x_d],axis=-1)\n",
    "    \n",
    "    x = Conv2D(filters = 32, kernel_size=(1,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "       \n",
    "    x = Conv2D(filters = 64, kernel_size=(1,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "      \n",
    "    model = Model([input_joints,input_joints_diff],x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def multi_obj2(frame_l=16, joint_n=25, joint_d=3):\n",
    "    inp_j_0 = Input(name='inp_j_0', shape=(frame_l, joint_n, joint_d))\n",
    "    \n",
    "    inp_j_diff_0 = Input(name='inp_j_diff_0', shape=(frame_l, joint_n, joint_d))\n",
    "    \n",
    "    \n",
    "    inp_j_1 = Input(name='inp_j_1', shape=(frame_l, joint_n, joint_d))\n",
    "    inp_j_diff_1 = Input(name='inp_j_diff_1', shape=(frame_l, joint_n, joint_d))\n",
    "    \n",
    "    single = one_obj2()\n",
    "    x_0 = single([inp_j_0,inp_j_diff_0])\n",
    "    x_1 = single([inp_j_1,inp_j_diff_1])\n",
    "      \n",
    "    x = Maximum()([x_0,x_1])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "     \n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Dense(6, activation='sigmoid')(x)\n",
    "      \n",
    "    model = Model([inp_j_0,inp_j_diff_0,inp_j_1,inp_j_diff_1],x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "lr=0.001\n",
    "adam = optimizers.Adam(lr)\n",
    "model2 = multi_obj2()\n",
    "model2.compile(adam, loss='mean_squared_error')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on X,Y,Z on my Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom1(p):\n",
    "    l = p.shape[0]\n",
    "    p_new = np.empty([16,25,3]) \n",
    "    for m in range(25):\n",
    "        for n in range(3):\n",
    "            p_new[:,m,n] = inter.zoom(p[:,m,n],16/l)[:16]\n",
    "    return p_new\n",
    "\n",
    "\n",
    "epochs = 400\n",
    "for e in range(epochs):\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    X_2 = []\n",
    "    X_3 = []\n",
    "    Y = []\n",
    "    i = -1\n",
    "    for root, dirs, files in os.walk(\"data/train\"):\n",
    "        if(i < 6):\n",
    "            i = i+1\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                skeleton_data = pd.read_csv(os.path.join(root, file), sep=\" \", header=None)\n",
    "                p_0 = skeleton_data.iloc[:,:75]\n",
    "                \n",
    "                p_0 = np.copy(p_0)                \n",
    "                p_0 = p_0.reshape([-1,25,3])\n",
    "                t_0 = p_0.shape[0]\n",
    "                if t_0>16:                   # sample the range from crop size of [16,t_0]\n",
    "                    ratio = np.random.uniform(1,t_0/16)\n",
    "                    l = int(16*ratio)\n",
    "                    start = random.sample(range(t_0-l),1)[0]\n",
    "                    end = start+l\n",
    "                    p_0 = p_0[start:end,:,:]\n",
    "                    p_0 = zoom1(p_0)\n",
    "                elif t_0<16:\n",
    "                    p_0 = zoom1(p_0)\n",
    "                \n",
    "                \n",
    "                #Second person pose                \n",
    "                p_1 = skeleton_data.iloc[:,75:]\n",
    "                \n",
    "                p_1 = np.copy(p_1)                \n",
    "                p_1 = p_1.reshape([-1,25,3])\n",
    "                t_1 = p_1.shape[0]\n",
    "                if t_1 >16:  \n",
    "                    ratio = np.random.uniform(1,t_1/16)\n",
    "                    l = int(16*ratio)\n",
    "                    start = random.sample(range(t_1-l),1)[0]\n",
    "                    end = start+l\n",
    "                    p_1 = p_1[start:end,:,:]\n",
    "                    p_1 = zoom1(p_1)\n",
    "                elif t_1 <16:\n",
    "                    p_1 = zoom1(p_1)\n",
    "\n",
    "                # randomly mirror augmentation \n",
    "                # since two persions' postion could be switched\n",
    "                if np.random.choice([0,1],1): \n",
    "                    p_0, p_1 = mirror(p_0,p_1)\n",
    "\n",
    "                #Calculate the temporal difference\n",
    "                p_0_diff = p_0[1:,:,:]-p_0[:-1,:,:]\n",
    "                #print(p_0[1:,:,:])\n",
    "                p_0_diff = np.concatenate((p_0_diff,np.expand_dims(p_0_diff[-1,:,:],axis=0)))\n",
    "                p_1_diff = p_1[1:,:,:]-p_1[:-1,:,:]\n",
    "                p_1_diff = np.concatenate((p_1_diff,np.expand_dims(p_1_diff[-1,:,:],axis=0)))\n",
    "\n",
    "                \n",
    "                X_0.append(p_0)\n",
    "                X_1.append(p_0_diff)\n",
    "                X_2.append(p_1)\n",
    "                X_3.append(p_1_diff)\n",
    "                \n",
    "                label = np.zeros(6)\n",
    "                label[i-1] = 1\n",
    "                Y.append(label)\n",
    "                \n",
    "   \n",
    "    X_0 = np.stack(X_0) \n",
    "    X_1 = np.stack(X_1)\n",
    "    X_2 = np.stack(X_2)\n",
    "    X_3 = np.stack(X_3)\n",
    "    Y = np.stack(Y) \n",
    "    \n",
    "    \n",
    "    history = model2.fit([X_0,X_1,X_2,X_3],Y,batch_size=32,epochs=1,verbose=True,shuffle=True)\n",
    "    \n",
    "    if not (e+1)%50:\n",
    "        lr *= 0.8\n",
    "        adam = optimizers.Adam(lr)\n",
    "        model2.compile(adam, loss='mean_squared_error')\n",
    "    \n",
    "    print(\"===================================================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on X,Y,Z on my Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom1(p):\n",
    "    l = p.shape[0]\n",
    "    #print(l)\n",
    "    p_new = np.empty([16,25,3]) \n",
    "    #print(p_new)\n",
    "    for m in range(25):\n",
    "        for n in range(3):\n",
    "            #print(m)\n",
    "            #print(n)\n",
    "            #print(p[:,m,n])\n",
    "            p_new[:,m,n] = inter.zoom(p[:,m,n],16/l)[:16]\n",
    "    return p_new\n",
    "\n",
    "i = -1\n",
    "X_TEST_0 = []\n",
    "X_TEST_1 = []\n",
    "X_TEST_2 = []\n",
    "X_TEST_3 = []\n",
    "Y_TEST = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"data/test\"):\n",
    "        if(i < 6):\n",
    "            i = i+1\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                skeleton_data = pd.read_csv(os.path.join(root, file), sep=\" \", header=None)\n",
    "                p_0 = skeleton_data.iloc[:,:75]\n",
    "                              \n",
    "                p_0 = np.copy(p_0)                \n",
    "                p_0 = p_0.reshape([-1,25,3])\n",
    "                t_0 = p_0.shape[0]\n",
    "                # if the number of frame is more than 20, crop by scale 0.9, then rescale by interploration again\n",
    "                if t_0>=20: \n",
    "                    p_0 = p_0[int(t_0*0.05):int(t_0*0.95),:,:]\n",
    "                    p_0 = zoom1(p_0)\n",
    "                elif t_0<20:\n",
    "                    p_0 = zoom1(p_0)\n",
    "                p_0_diff = p_0[1:,:,:]-p_0[:-1,:,:]\n",
    "                p_0_diff = np.concatenate((p_0_diff,np.expand_dims(p_0_diff[-1,:,:],axis=0)))\n",
    "                \n",
    "                \n",
    "                p_1 = skeleton_data.iloc[:,75:]                           \n",
    "                \n",
    "                p_1 = np.copy(p_1)\n",
    "                p_1 = p_1.reshape([-1,25,3])\n",
    "                t_1 = p_1.shape[0]\n",
    "                if t_1 >=20:  \n",
    "                    p_1 = p_1[int(t_1*0.05):int(t_1*0.95),:,:]\n",
    "                    p_1 = zoom1(p_1)\n",
    "                elif t_1 <20:\n",
    "                    p_1 = zoom1(p_1)\n",
    "                p_1_diff = p_1[1:,:,:]-p_1[:-1,:,:]\n",
    "                p_1_diff = np.concatenate((p_1_diff,np.expand_dims(p_1_diff[-1,:,:],axis=0)))\n",
    "\n",
    "                X_TEST_0.append(p_0)\n",
    "                X_TEST_1.append(p_0_diff)\n",
    "                X_TEST_2.append(p_1)\n",
    "                X_TEST_3.append(p_1_diff)\n",
    "               \n",
    "                label = np.zeros(6)\n",
    "                label[i-1] = 1\n",
    "                #print(label)\n",
    "                Y_TEST.append(label)\n",
    "\n",
    "X_TEST_0 = np.stack(X_TEST_0)\n",
    "X_TEST_1 = np.stack(X_TEST_1)\n",
    "X_TEST_2 = np.stack(X_TEST_2)\n",
    "X_TEST_3 = np.stack(X_TEST_3)\n",
    "Y_TEST = np.stack(Y_TEST)\n",
    "\n",
    "Y_pred = model2.predict([X_TEST_0,X_TEST_1,X_TEST_2,X_TEST_3])\n",
    "\n",
    "print('Predict labels:     ',np.argmax(Y_pred,axis=1))\n",
    "print('Ground truth labels:',np.argmax(Y_TEST,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_true = 0\n",
    "predicted_labels = np.argmax(Y_pred,axis=1)\n",
    "ground_truth_labels = np.argmax(Y_TEST,axis=1)\n",
    "for i in range(len(predicted_labels)):\n",
    "    if(predicted_labels[i] == ground_truth_labels[i]):\n",
    "        predicted_true +=1\n",
    "print(predicted_true/len(predicted_labels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
